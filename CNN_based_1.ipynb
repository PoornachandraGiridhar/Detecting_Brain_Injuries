{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJWCcLlHA15o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft,fft2, fftshift\n",
        "from skimage.io import imread\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWo2wCeiA15p"
      },
      "outputs": [],
      "source": [
        "# sino=np.load('/mnt/DATA/EE21B040/Downloads/sinograms_3W_test/ID_0a1f2c77b.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK066O0HA15p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_folder, csv_file,transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_folder (str): Path to the folder containing images.\n",
        "            csv_file (str): Path to the CSV file with image names and labels.\n",
        "            transform (callable, optional): Optional transform to be applied on the image.\n",
        "        \"\"\"\n",
        "        self.img_folder = img_folder\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Extract image file names and labels from the CSV file\n",
        "        self.img_files = self.df['Image'].values\n",
        "        self.labels = self.df['any'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the length of the dataset (number of samples)\n",
        "        return len(self.img_files)\n",
        "    def __getitem__(self, index):\n",
        "    # Load the image file\n",
        "        img_filename = self.img_files[index]\n",
        "        img_path = os.path.join(self.img_folder, f\"{img_filename}.npy\")  # Construct the .npy file path\n",
        "\n",
        "    # Load the image as a NumPy array from the .npy file\n",
        "        image = np.load(img_path)\n",
        "        num_angles = image.shape[0]\n",
        "        num_channels = image.shape[2]\n",
        "        for angle_index in range(num_angles):\n",
        "                # Iterate over each channel\n",
        "            for channel_index in range(num_channels):\n",
        "                    # Apply Fourier transform to the current channel at the current angle\n",
        "                image[angle_index, :, channel_index] = abs(fft(image[angle_index, :, channel_index]))\n",
        "\n",
        "    # Convert the NumPy array to a PyTorch tensor\n",
        "\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image=image.permute(2,0,1)\n",
        "\n",
        "    # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "    # Get the label\n",
        "        label = self.labels[index]\n",
        "\n",
        "    # Convert the label to a PyTorch tensor (if necessary)\n",
        "        #label = torch.tensor(label, dtype=torch.float32)\n",
        "        label = torch.tensor([label], dtype=torch.float32)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eExcGr5lA15q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "\n",
        "train_img_folder ='/mnt/DATA/sinograms_3W_train'  # Replace with your image folder path\n",
        "train_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/train_x.csv'  # Replace with your CSV file path\n",
        "train_dataset = CustomDataset(train_img_folder, train_csv_file)\n",
        "\n",
        "test_img_folder ='/mnt/DATA/EE21B040/Downloads/sinograms_3W_test' # Replace with your image folder path\n",
        "test_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/test_x.csv' # Replace with your CSV file path\n",
        "test_dataset = CustomDataset(test_img_folder, test_csv_file)\n",
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=True,drop_last=True)\n",
        "\n",
        "# Set the random seed for reproducibility (optional)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Get the length of your train_dataset\n",
        "dataset_length = len(train_dataset)\n",
        "\n",
        "# Generate a list of indices from 0 to dataset_length\n",
        "indices = list(range(dataset_length))\n",
        "\n",
        "# Shuffle the indices\n",
        "torch.random.manual_seed(42)  # Set random seed for reproducibility\n",
        "# torch.random.shuffle(indices)\n",
        "indices = torch.randperm(dataset_length)\n",
        "indices = indices.tolist()\n",
        "# Select 20,000 random indices\n",
        "selected_indices = indices[:75000]\n",
        "\n",
        "# Create a SubsetRandomSampler using the selected indices\n",
        "subset_sampler = SubsetRandomSampler(selected_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, sampler=subset_sampler,drop_last=True)\n",
        "valid_img_folder ='/mnt/DATA/sinograms_3W_train'  # Replace with your image folder path\n",
        "valid_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/valid_x.csv' # Replace with your CSV file path\n",
        "valid_dataset = CustomDataset(valid_img_folder, valid_csv_file)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=50, shuffle=True,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKyNgjP9A15q",
        "outputId": "cf274a7c-07d4-4b1a-fa8a-dedafc801b4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25783"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMJ7HdOPA15r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BinaryClassificationCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassificationCNN, self).__init__()\n",
        "\n",
        "        # Define convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Define pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Run a sample image through the conv and pool layers to find the correct input size for fc1\n",
        "        # Assuming input shape is (1, 3, 360, 362)\n",
        "        sample_input = torch.randn(1, 3, 360, 362)\n",
        "        sample_output = self.pool(F.relu(self.conv1(sample_input)))\n",
        "        sample_output = self.pool(F.relu(self.conv2(sample_output)))\n",
        "        sample_output = self.pool(F.relu(self.conv3(sample_output)))\n",
        "        fc1_input_size = sample_output.numel()  # Calculate input size\n",
        "\n",
        "        # Define fully connected layers with the correct input size\n",
        "        self.fc1 = nn.Linear(fc1_input_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Flatten the tensor for fully connected layers\n",
        "        # x = x.view(x.size(0), -1)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Output layer for binary classification using sigmoid activation\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjrbqoyYA15r",
        "outputId": "3f10ffa7-0972-4f53-d981-dca441f6dccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50, 3, 360, 362])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in train_loader:\n",
        "        print(images.shape)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_gv8XSjA15r",
        "outputId": "bab52e97-5ec0-47a9-b506-375203d56bd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "515"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7LDMis-A15s",
        "outputId": "2a315865-f34b-4a0f-ac6a-7915b9302a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Batch 100/1500, Loss: 0.5103228688240051\n",
            "Epoch 1, Batch 200/1500, Loss: 0.5002064108848572\n",
            "Epoch 1, Batch 300/1500, Loss: 0.4453103244304657\n",
            "Epoch 1, Batch 400/1500, Loss: 0.5725246071815491\n",
            "Epoch 1, Batch 500/1500, Loss: 0.5299974083900452\n",
            "Epoch 1, Batch 600/1500, Loss: 0.46316078305244446\n",
            "Epoch 1, Batch 700/1500, Loss: 0.47291257977485657\n",
            "Epoch 1, Batch 800/1500, Loss: 0.5011010766029358\n",
            "Epoch 1, Batch 900/1500, Loss: 0.47148871421813965\n",
            "Epoch 1, Batch 1000/1500, Loss: 0.4746263027191162\n",
            "Epoch 1, Batch 1100/1500, Loss: 0.5872865915298462\n",
            "Epoch 1, Batch 1200/1500, Loss: 0.4974919855594635\n",
            "Epoch 1, Batch 1300/1500, Loss: 0.5020282864570618\n",
            "Epoch 1, Batch 1400/1500, Loss: 0.4351782202720642\n",
            "Epoch 1, Batch 1500/1500, Loss: 0.45801085233688354\n",
            "Epoch 1/15, Train Loss: 0.5712, Train Accuracy: 0.7156, Validation Loss: 0.4792, Validation Accuracy: 0.7021\n",
            "Epoch 1 completed in 4802.10 seconds\n",
            "Epoch 2, Batch 100/1500, Loss: 0.4278680384159088\n",
            "Epoch 2, Batch 200/1500, Loss: 0.5431684255599976\n",
            "Epoch 2, Batch 300/1500, Loss: 0.37976375222206116\n",
            "Epoch 2, Batch 400/1500, Loss: 0.4723336398601532\n",
            "Epoch 2, Batch 500/1500, Loss: 0.4107701778411865\n",
            "Epoch 2, Batch 600/1500, Loss: 0.4685378670692444\n",
            "Epoch 2, Batch 700/1500, Loss: 0.5473204851150513\n",
            "Epoch 2, Batch 800/1500, Loss: 0.3853895366191864\n",
            "Epoch 2, Batch 900/1500, Loss: 0.45867210626602173\n",
            "Epoch 2, Batch 1000/1500, Loss: 0.5689935684204102\n",
            "Epoch 2, Batch 1100/1500, Loss: 0.5201789140701294\n",
            "Epoch 2, Batch 1200/1500, Loss: 0.5163676142692566\n",
            "Epoch 2, Batch 1300/1500, Loss: 0.3799389600753784\n",
            "Epoch 2, Batch 1400/1500, Loss: 0.42934852838516235\n",
            "Epoch 2, Batch 1500/1500, Loss: 0.46702441573143005\n",
            "Epoch 2/15, Train Loss: 0.4432, Train Accuracy: 0.7562, Validation Loss: 0.4817, Validation Accuracy: 0.7301\n",
            "Epoch 2 completed in 3651.32 seconds\n",
            "Epoch 3, Batch 100/1500, Loss: 0.4157714247703552\n",
            "Epoch 3, Batch 200/1500, Loss: 0.41448283195495605\n",
            "Epoch 3, Batch 300/1500, Loss: 0.32310622930526733\n",
            "Epoch 3, Batch 400/1500, Loss: 0.2634582817554474\n",
            "Epoch 3, Batch 500/1500, Loss: 0.4049781560897827\n",
            "Epoch 3, Batch 600/1500, Loss: 0.3345243036746979\n",
            "Epoch 3, Batch 700/1500, Loss: 0.37037843465805054\n",
            "Epoch 3, Batch 800/1500, Loss: 0.24148257076740265\n",
            "Epoch 3, Batch 900/1500, Loss: 0.2610606253147125\n",
            "Epoch 3, Batch 1000/1500, Loss: 0.26559874415397644\n",
            "Epoch 3, Batch 1100/1500, Loss: 0.3269856572151184\n",
            "Epoch 3, Batch 1200/1500, Loss: 0.4376397728919983\n",
            "Epoch 3, Batch 1300/1500, Loss: 0.29291635751724243\n",
            "Epoch 3, Batch 1400/1500, Loss: 0.26438093185424805\n",
            "Epoch 3, Batch 1500/1500, Loss: 0.4313429296016693\n",
            "Epoch 3/15, Train Loss: 0.3518, Train Accuracy: 0.8196, Validation Loss: 0.5658, Validation Accuracy: 0.7369\n",
            "Epoch 3 completed in 4281.04 seconds\n",
            "Epoch 4, Batch 100/1500, Loss: 0.1636790931224823\n",
            "Epoch 4, Batch 200/1500, Loss: 0.1181182712316513\n",
            "Epoch 4, Batch 300/1500, Loss: 0.2176714986562729\n",
            "Epoch 4, Batch 400/1500, Loss: 0.1822478026151657\n",
            "Epoch 4, Batch 500/1500, Loss: 0.2803024351596832\n",
            "Epoch 4, Batch 600/1500, Loss: 0.15389639139175415\n",
            "Epoch 4, Batch 700/1500, Loss: 0.10924772173166275\n",
            "Epoch 4, Batch 800/1500, Loss: 0.15616752207279205\n",
            "Epoch 4, Batch 900/1500, Loss: 0.1631375253200531\n",
            "Epoch 4, Batch 1000/1500, Loss: 0.13437588512897491\n",
            "Epoch 4, Batch 1100/1500, Loss: 0.12287556380033493\n",
            "Epoch 4, Batch 1200/1500, Loss: 0.2866831421852112\n",
            "Epoch 4, Batch 1300/1500, Loss: 0.09702549129724503\n",
            "Epoch 4, Batch 1400/1500, Loss: 0.3756372630596161\n",
            "Epoch 4, Batch 1500/1500, Loss: 0.17779523134231567\n",
            "Epoch 4/15, Train Loss: 0.1900, Train Accuracy: 0.9157, Validation Loss: 0.7097, Validation Accuracy: 0.7021\n",
            "Epoch 4 completed in 2793.35 seconds\n",
            "Epoch 5, Batch 100/1500, Loss: 0.04024571180343628\n",
            "Epoch 5, Batch 200/1500, Loss: 0.029097000136971474\n",
            "Epoch 5, Batch 300/1500, Loss: 0.049760445952415466\n",
            "Epoch 5, Batch 400/1500, Loss: 0.14503611624240875\n",
            "Epoch 5, Batch 500/1500, Loss: 0.033045683056116104\n",
            "Epoch 5, Batch 600/1500, Loss: 0.04733449965715408\n",
            "Epoch 5, Batch 700/1500, Loss: 0.3048347532749176\n",
            "Epoch 5, Batch 800/1500, Loss: 0.05774210765957832\n",
            "Epoch 5, Batch 900/1500, Loss: 0.08647985011339188\n",
            "Epoch 5, Batch 1000/1500, Loss: 0.10908263176679611\n",
            "Epoch 5, Batch 1100/1500, Loss: 0.07451995462179184\n",
            "Epoch 5, Batch 1200/1500, Loss: 0.12890325486660004\n",
            "Epoch 5, Batch 1300/1500, Loss: 0.1428096443414688\n",
            "Epoch 5, Batch 1400/1500, Loss: 0.014367606490850449\n",
            "Epoch 5, Batch 1500/1500, Loss: 0.07066717743873596\n",
            "Epoch 5/15, Train Loss: 0.0758, Train Accuracy: 0.9705, Validation Loss: 0.9303, Validation Accuracy: 0.7260\n",
            "Epoch 5 completed in 2684.69 seconds\n",
            "Epoch 6, Batch 100/1500, Loss: 0.024881400167942047\n",
            "Epoch 6, Batch 200/1500, Loss: 0.01663968153297901\n",
            "Epoch 6, Batch 300/1500, Loss: 0.007106834556907415\n",
            "Epoch 6, Batch 400/1500, Loss: 0.06423969566822052\n",
            "Epoch 6, Batch 500/1500, Loss: 0.025636868551373482\n",
            "Epoch 6, Batch 600/1500, Loss: 0.06926366686820984\n",
            "Epoch 6, Batch 700/1500, Loss: 0.1325724571943283\n",
            "Epoch 6, Batch 800/1500, Loss: 0.1438557654619217\n",
            "Epoch 6, Batch 900/1500, Loss: 0.03970707952976227\n",
            "Epoch 6, Batch 1000/1500, Loss: 0.014820377342402935\n",
            "Epoch 6, Batch 1100/1500, Loss: 0.08287826180458069\n",
            "Epoch 6, Batch 1200/1500, Loss: 0.09878285974264145\n",
            "Epoch 6, Batch 1300/1500, Loss: 0.03305232897400856\n",
            "Epoch 6, Batch 1400/1500, Loss: 0.044754404574632645\n",
            "Epoch 6, Batch 1500/1500, Loss: 0.2742230296134949\n",
            "Epoch 6/15, Train Loss: 0.0497, Train Accuracy: 0.9815, Validation Loss: 1.1718, Validation Accuracy: 0.7336\n",
            "Epoch 6 completed in 2667.54 seconds\n",
            "Epoch 7, Batch 100/1500, Loss: 0.1454867422580719\n",
            "Epoch 7, Batch 200/1500, Loss: 0.0047443159855902195\n",
            "Epoch 7, Batch 300/1500, Loss: 0.018022892996668816\n",
            "Epoch 7, Batch 400/1500, Loss: 0.07060423493385315\n",
            "Epoch 7, Batch 500/1500, Loss: 0.00923000555485487\n",
            "Epoch 7, Batch 600/1500, Loss: 0.08685034513473511\n",
            "Epoch 7, Batch 700/1500, Loss: 0.01215122826397419\n",
            "Epoch 7, Batch 800/1500, Loss: 0.01730373315513134\n",
            "Epoch 7, Batch 900/1500, Loss: 0.033521924167871475\n",
            "Epoch 7, Batch 1000/1500, Loss: 0.017412154003977776\n",
            "Epoch 7, Batch 1100/1500, Loss: 0.01573031395673752\n",
            "Epoch 7, Batch 1200/1500, Loss: 0.12865090370178223\n",
            "Epoch 7, Batch 1300/1500, Loss: 0.024081634357571602\n",
            "Epoch 7, Batch 1400/1500, Loss: 0.04414092376828194\n",
            "Epoch 7, Batch 1500/1500, Loss: 0.05740000680088997\n",
            "Epoch 7/15, Train Loss: 0.0437, Train Accuracy: 0.9834, Validation Loss: 1.2955, Validation Accuracy: 0.7254\n",
            "Epoch 7 completed in 2694.93 seconds\n",
            "Epoch 8, Batch 100/1500, Loss: 0.002775943838059902\n",
            "Epoch 8, Batch 200/1500, Loss: 0.018023677170276642\n",
            "Epoch 8, Batch 300/1500, Loss: 0.10249584168195724\n",
            "Epoch 8, Batch 400/1500, Loss: 0.010665769688785076\n",
            "Epoch 8, Batch 500/1500, Loss: 0.011029538698494434\n",
            "Epoch 8, Batch 600/1500, Loss: 0.005124053917825222\n",
            "Epoch 8, Batch 700/1500, Loss: 0.0272991880774498\n",
            "Epoch 8, Batch 800/1500, Loss: 0.050719253718853\n",
            "Epoch 8, Batch 900/1500, Loss: 0.009541957639157772\n",
            "Epoch 8, Batch 1000/1500, Loss: 0.16428133845329285\n",
            "Epoch 8, Batch 1100/1500, Loss: 0.008572176098823547\n",
            "Epoch 8, Batch 1200/1500, Loss: 0.01219912525266409\n",
            "Epoch 8, Batch 1300/1500, Loss: 0.009906250052154064\n",
            "Epoch 8, Batch 1400/1500, Loss: 0.003059856127947569\n",
            "Epoch 8, Batch 1500/1500, Loss: 0.024040646851062775\n",
            "Epoch 8/15, Train Loss: 0.0400, Train Accuracy: 0.9849, Validation Loss: 1.3025, Validation Accuracy: 0.7299\n",
            "Epoch 8 completed in 2711.26 seconds\n",
            "Epoch 9, Batch 100/1500, Loss: 0.005516066215932369\n",
            "Epoch 9, Batch 200/1500, Loss: 0.10950754582881927\n",
            "Epoch 9, Batch 300/1500, Loss: 0.05493854358792305\n",
            "Epoch 9, Batch 400/1500, Loss: 0.020424572750926018\n",
            "Epoch 9, Batch 500/1500, Loss: 0.030054248869419098\n",
            "Epoch 9, Batch 600/1500, Loss: 0.003983359318226576\n",
            "Epoch 9, Batch 700/1500, Loss: 0.08670500665903091\n",
            "Epoch 9, Batch 800/1500, Loss: 0.028578395023941994\n",
            "Epoch 9, Batch 900/1500, Loss: 0.008300216868519783\n",
            "Epoch 9, Batch 1000/1500, Loss: 0.024203810840845108\n",
            "Epoch 9, Batch 1100/1500, Loss: 0.03682354465126991\n",
            "Epoch 9, Batch 1200/1500, Loss: 0.03650490567088127\n",
            "Epoch 9, Batch 1300/1500, Loss: 0.0003898020077031106\n",
            "Epoch 9, Batch 1400/1500, Loss: 0.025402164086699486\n",
            "Epoch 9, Batch 1500/1500, Loss: 0.084178626537323\n",
            "Epoch 9/15, Train Loss: 0.0339, Train Accuracy: 0.9872, Validation Loss: 1.3483, Validation Accuracy: 0.7110\n",
            "Epoch 9 completed in 2705.06 seconds\n",
            "Epoch 10, Batch 100/1500, Loss: 0.008851010352373123\n",
            "Epoch 10, Batch 200/1500, Loss: 0.05732444301247597\n",
            "Epoch 10, Batch 300/1500, Loss: 0.04175369814038277\n",
            "Epoch 10, Batch 400/1500, Loss: 0.17164960503578186\n",
            "Epoch 10, Batch 500/1500, Loss: 0.05917702615261078\n",
            "Epoch 10, Batch 600/1500, Loss: 0.004270304460078478\n",
            "Epoch 10, Batch 700/1500, Loss: 0.010961757972836494\n",
            "Epoch 10, Batch 800/1500, Loss: 0.038767505437135696\n",
            "Epoch 10, Batch 900/1500, Loss: 0.012031936086714268\n",
            "Epoch 10, Batch 1000/1500, Loss: 0.0900886133313179\n",
            "Epoch 10, Batch 1100/1500, Loss: 0.03311532735824585\n",
            "Epoch 10, Batch 1200/1500, Loss: 0.006457943934947252\n",
            "Epoch 10, Batch 1300/1500, Loss: 0.022015878930687904\n",
            "Epoch 10, Batch 1400/1500, Loss: 0.0746266320347786\n",
            "Epoch 10, Batch 1500/1500, Loss: 0.06636279821395874\n",
            "Epoch 10/15, Train Loss: 0.0331, Train Accuracy: 0.9880, Validation Loss: 1.1931, Validation Accuracy: 0.7023\n",
            "Epoch 10 completed in 2705.17 seconds\n",
            "Epoch 11, Batch 100/1500, Loss: 0.014466634951531887\n",
            "Epoch 11, Batch 200/1500, Loss: 0.02906121127307415\n",
            "Epoch 11, Batch 300/1500, Loss: 0.0011607882333919406\n",
            "Epoch 11, Batch 400/1500, Loss: 0.01815160922706127\n",
            "Epoch 11, Batch 500/1500, Loss: 0.0174797922372818\n",
            "Epoch 11, Batch 600/1500, Loss: 0.011745292693376541\n",
            "Epoch 11, Batch 700/1500, Loss: 0.008531013503670692\n",
            "Epoch 11, Batch 800/1500, Loss: 0.047326840460300446\n",
            "Epoch 11, Batch 900/1500, Loss: 0.0009606711100786924\n",
            "Epoch 11, Batch 1000/1500, Loss: 0.025654666125774384\n",
            "Epoch 11, Batch 1100/1500, Loss: 0.01928342692553997\n",
            "Epoch 11, Batch 1200/1500, Loss: 0.010146035812795162\n",
            "Epoch 11, Batch 1300/1500, Loss: 0.02453668974339962\n",
            "Epoch 11, Batch 1400/1500, Loss: 0.00216451077722013\n",
            "Epoch 11, Batch 1500/1500, Loss: 0.003042760770767927\n",
            "Epoch 11/15, Train Loss: 0.0267, Train Accuracy: 0.9899, Validation Loss: 1.6929, Validation Accuracy: 0.7313\n",
            "Epoch 11 completed in 2611.99 seconds\n",
            "Epoch 12, Batch 100/1500, Loss: 0.0020701962057501078\n",
            "Epoch 12, Batch 200/1500, Loss: 0.02032180316746235\n",
            "Epoch 12, Batch 300/1500, Loss: 0.008162730373442173\n",
            "Epoch 12, Batch 400/1500, Loss: 0.0012728030560538173\n",
            "Epoch 12, Batch 500/1500, Loss: 0.0380244143307209\n",
            "Epoch 12, Batch 600/1500, Loss: 0.0021157441660761833\n",
            "Epoch 12, Batch 700/1500, Loss: 0.025073952972888947\n",
            "Epoch 12, Batch 800/1500, Loss: 0.022825514897704124\n",
            "Epoch 12, Batch 900/1500, Loss: 0.03414835408329964\n",
            "Epoch 12, Batch 1000/1500, Loss: 0.003335847519338131\n",
            "Epoch 12, Batch 1100/1500, Loss: 0.04368533194065094\n",
            "Epoch 12, Batch 1200/1500, Loss: 0.005097489338368177\n",
            "Epoch 12, Batch 1300/1500, Loss: 0.06449782103300095\n",
            "Epoch 12, Batch 1400/1500, Loss: 0.009622999466955662\n",
            "Epoch 12, Batch 1500/1500, Loss: 0.005662824958562851\n",
            "Epoch 12/15, Train Loss: 0.0248, Train Accuracy: 0.9908, Validation Loss: 1.4158, Validation Accuracy: 0.7157\n",
            "Epoch 12 completed in 2703.60 seconds\n",
            "Epoch 13, Batch 100/1500, Loss: 0.002605278044939041\n",
            "Epoch 13, Batch 200/1500, Loss: 0.03811555355787277\n",
            "Epoch 13, Batch 300/1500, Loss: 0.0008410396403633058\n",
            "Epoch 13, Batch 400/1500, Loss: 0.003479915438219905\n",
            "Epoch 13, Batch 500/1500, Loss: 0.017176128923892975\n",
            "Epoch 13, Batch 600/1500, Loss: 0.003698811400681734\n",
            "Epoch 13, Batch 700/1500, Loss: 0.27865907549858093\n",
            "Epoch 13, Batch 800/1500, Loss: 0.02073172852396965\n",
            "Epoch 13, Batch 900/1500, Loss: 0.125064879655838\n",
            "Epoch 13, Batch 1000/1500, Loss: 0.12465250492095947\n",
            "Epoch 13, Batch 1100/1500, Loss: 0.0017028403235599399\n",
            "Epoch 13, Batch 1200/1500, Loss: 0.050452928990125656\n",
            "Epoch 13, Batch 1300/1500, Loss: 0.018394283950328827\n",
            "Epoch 13, Batch 1400/1500, Loss: 0.058470871299505234\n",
            "Epoch 13, Batch 1500/1500, Loss: 0.15202753245830536\n",
            "Epoch 13/15, Train Loss: 0.0263, Train Accuracy: 0.9902, Validation Loss: 1.4917, Validation Accuracy: 0.7166\n",
            "Epoch 13 completed in 2597.05 seconds\n",
            "Epoch 14, Batch 100/1500, Loss: 0.1528848260641098\n",
            "Epoch 14, Batch 200/1500, Loss: 0.0007841406622901559\n",
            "Epoch 14, Batch 300/1500, Loss: 0.0005461153341457248\n",
            "Epoch 14, Batch 400/1500, Loss: 0.001228775829076767\n",
            "Epoch 14, Batch 500/1500, Loss: 0.01563168875873089\n",
            "Epoch 14, Batch 600/1500, Loss: 0.007163252681493759\n",
            "Epoch 14, Batch 700/1500, Loss: 0.0004636496596504003\n",
            "Epoch 14, Batch 800/1500, Loss: 0.010782524012029171\n",
            "Epoch 14, Batch 900/1500, Loss: 0.0045780292712152\n",
            "Epoch 14, Batch 1000/1500, Loss: 0.011934783309698105\n",
            "Epoch 14, Batch 1100/1500, Loss: 0.004800260066986084\n",
            "Epoch 14, Batch 1200/1500, Loss: 0.01580793969333172\n",
            "Epoch 14, Batch 1300/1500, Loss: 0.08805207908153534\n",
            "Epoch 14, Batch 1400/1500, Loss: 0.018292902037501335\n",
            "Epoch 14, Batch 1500/1500, Loss: 0.0004903049557469785\n",
            "Epoch 14/15, Train Loss: 0.0195, Train Accuracy: 0.9929, Validation Loss: 1.7666, Validation Accuracy: 0.7223\n",
            "Epoch 14 completed in 2698.68 seconds\n",
            "Epoch 15, Batch 100/1500, Loss: 0.013312574476003647\n",
            "Epoch 15, Batch 200/1500, Loss: 0.0006584704387933016\n",
            "Epoch 15, Batch 300/1500, Loss: 0.003607599763199687\n",
            "Epoch 15, Batch 400/1500, Loss: 0.013847743161022663\n",
            "Epoch 15, Batch 500/1500, Loss: 0.019590627402067184\n",
            "Epoch 15, Batch 600/1500, Loss: 0.015028566122055054\n",
            "Epoch 15, Batch 700/1500, Loss: 0.0020003921817988157\n",
            "Epoch 15, Batch 800/1500, Loss: 0.0015194150619208813\n",
            "Epoch 15, Batch 900/1500, Loss: 0.046099256724119186\n",
            "Epoch 15, Batch 1000/1500, Loss: 0.08403243124485016\n",
            "Epoch 15, Batch 1100/1500, Loss: 0.17279596626758575\n",
            "Epoch 15, Batch 1200/1500, Loss: 0.004181781783699989\n",
            "Epoch 15, Batch 1300/1500, Loss: 0.0015635272720828652\n",
            "Epoch 15, Batch 1400/1500, Loss: 0.014162587933242321\n",
            "Epoch 15, Batch 1500/1500, Loss: 0.0618271566927433\n",
            "Epoch 15/15, Train Loss: 0.0220, Train Accuracy: 0.9915, Validation Loss: 1.8772, Validation Accuracy: 0.7141\n",
            "Epoch 15 completed in 3149.56 seconds\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA (GPU) is available\n",
        "model = BinaryClassificationCNN()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Instantiate the model and move it to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # For binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "# Define the ModelCheckpoint function to save the model every 10 epochs\n",
        "def save_checkpoint(epoch):\n",
        "    torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')\n",
        "\n",
        "import time\n",
        "import time\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Start the timer for the epoch\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    # Training loop\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move images and labels to the device (GPU or CPU)\n",
        "        # images = images.permute(0, 3, 1, 2)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Reshape labels to match model output shape\n",
        "        labels = labels.view(-1, 1)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        predictions = (outputs >= 0.5).float()  # Apply threshold to outputs\n",
        "        train_correct += (predictions == labels.float()).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print batch progress\n",
        "        if (i + 1) % 100 == 0:  # Modify this line to adjust the frequency of progress printing\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}/{len(train_loader)}, Loss: {loss.item()}')\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    train_accuracy = train_correct / train_total\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            # Move images and labels to the device (GPU or CPU)\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            labels = labels.view(-1, 1)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate the number of correct predictions\n",
        "            predictions = (outputs >= 0.5).float()  # Apply threshold to outputs\n",
        "            val_correct += (predictions == labels.float()).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    val_loss /= len(valid_loader)\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    # Print progress\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
        "          f'Train Loss: {train_loss / len(train_loader):.4f}, '\n",
        "          f'Train Accuracy: {train_accuracy:.4f}, '\n",
        "          f'Validation Loss: {val_loss:.4f}, '\n",
        "          f'Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # Calculate and print the time taken for the epoch\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f'Epoch {epoch + 1} completed in {epoch_time:.2f} seconds')\n",
        "\n",
        "    # Save the model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        save_checkpoint(epoch + 1)\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5RE2csKA15s",
        "outputId": "411caf97-a484-4654-caf0-be4965e83d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 1.8267, Test Accuracy: 0.7154\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move images and labels to the device (GPU or CPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Reshape labels to match model output shape\n",
        "        labels = labels.view(-1, 1)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        predictions = (outputs >= 0.5).float()  # Apply threshold to outputs\n",
        "        test_correct += (predictions == labels.float()).sum().item()\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "# Calculate average test loss\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = test_correct / test_total\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dlh",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}