{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSyQ5SGiAWjZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft,fft2, fftshift\n",
        "from skimage.io import imread\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmHzK8MIAWja"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_folder, csv_file,transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_folder (str): Path to the folder containing images.\n",
        "            csv_file (str): Path to the CSV file with image names and labels.\n",
        "            transform (callable, optional): Optional transform to be applied on the image.\n",
        "        \"\"\"\n",
        "        self.img_folder = img_folder\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Extract image file names and labels from the CSV file\n",
        "        self.img_files = self.df['Image'].values\n",
        "        self.labels = self.df['any'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the length of the dataset (number of samples)\n",
        "        return len(self.img_files)\n",
        "    def __getitem__(self, index):\n",
        "    # Load the image file\n",
        "        img_filename = self.img_files[index]\n",
        "        img_path = os.path.join(self.img_folder, f\"{img_filename}.npy\")  # Construct the .npy file path\n",
        "\n",
        "    # Load the image as a NumPy array from the .npy file\n",
        "        image = np.load(img_path)\n",
        "        num_angles = image.shape[0]\n",
        "        num_channels = image.shape[2]\n",
        "        for angle_index in range(num_angles):\n",
        "                # Iterate over each channel\n",
        "            for channel_index in range(num_channels):\n",
        "                    # Apply Fourier transform to the current channel at the current angle\n",
        "                image[angle_index, :, channel_index] = abs(fft(image[angle_index, :, channel_index]))\n",
        "\n",
        "    # Convert the NumPy array to a PyTorch tensor\n",
        "\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image=image.permute(2,0,1)\n",
        "\n",
        "    # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "    # Get the label\n",
        "        label = self.labels[index]\n",
        "\n",
        "    # Convert the label to a PyTorch tensor (if necessary)\n",
        "        #label = torch.tensor(label, dtype=torch.float32)\n",
        "        label = torch.tensor([label], dtype=torch.float32)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFgMzWQ9AWjb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "\n",
        "train_img_folder ='/mnt/DATA/sinograms_3W_train'  # Replace with your image folder path\n",
        "train_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/train_x.csv'  # Replace with your CSV file path\n",
        "train_dataset = CustomDataset(train_img_folder, train_csv_file)\n",
        "\n",
        "test_img_folder ='/mnt/DATA/EE21B040/Downloads/sinograms_3W_test' # Replace with your image folder path\n",
        "test_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/test_x.csv' # Replace with your CSV file path\n",
        "test_dataset = CustomDataset(test_img_folder, test_csv_file)\n",
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=True,drop_last=True)\n",
        "\n",
        "# Set the random seed for reproducibility (optional)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Get the length of your train_dataset\n",
        "dataset_length = len(train_dataset)\n",
        "\n",
        "# Generate a list of indices from 0 to dataset_length\n",
        "indices = list(range(dataset_length))\n",
        "\n",
        "# Shuffle the indices\n",
        "torch.random.manual_seed(42)  # Set random seed for reproducibility\n",
        "# torch.random.shuffle(indices)\n",
        "indices = torch.randperm(dataset_length)\n",
        "indices = indices.tolist()\n",
        "# Select 20,000 random indices\n",
        "selected_indices = indices[:30000]\n",
        "\n",
        "# Create a SubsetRandomSampler using the selected indices\n",
        "subset_sampler = SubsetRandomSampler(selected_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, sampler=subset_sampler,drop_last=True)\n",
        "valid_img_folder ='/mnt/DATA/sinograms_3W_train'  # Replace with your image folder path\n",
        "valid_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/valid_x.csv' # Replace with your CSV file path\n",
        "valid_dataset = CustomDataset(valid_img_folder, valid_csv_file)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=50, shuffle=True,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCRqvKuoAWjb"
      },
      "outputs": [],
      "source": [
        "class BinaryClassificationCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassificationCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 45 * 45, 256)\n",
        "        self.fc2 = nn.Linear(256, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 45 * 45)\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFhRTlFvAWjb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "learning_rate=0.0001\n",
        "num_epochs=15\n",
        "model = BinaryClassificationCNN()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the ModelCheckpoint function to save the model every 10 epochs\n",
        "def save_checkpoint(epoch):\n",
        "    torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')\n",
        "\n",
        "# Training loop\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "train_accuracies = []\n",
        "valid_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        predicted = (outputs >= 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "    train_accuracies.append(correct / total)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            predicted = (outputs >= 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    valid_losses.append(valid_loss / len(valid_loader))\n",
        "    valid_accuracies.append(correct / total)\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, '\n",
        "          f'Valid Loss: {valid_losses[-1]:.4f}, Valid Acc: {valid_accuracies[-1]:.4f}')\n",
        "\n",
        "    # Save the model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        save_checkpoint(epoch + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cLyOjoaAWjc"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        predicted = (outputs >= 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct / total\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}')\n",
        "\n",
        "# Plotting training and validation curves\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(valid_losses, label='Valid Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(valid_accuracies, label='Valid Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8BRWih4AWjc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dlh_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}