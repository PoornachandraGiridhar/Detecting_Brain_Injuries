{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FIfFTQa_qzU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import numpy as np\n",
        "\n",
        "# Define your custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label\n",
        "\n",
        "# Assuming you have your data stored in numpy arrays: train_data, train_labels, test_data, test_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-VWly3S_qzW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.fft import fft,fft2, fftshift\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_folder, csv_file,transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_folder (str): Path to the folder containing images.\n",
        "            csv_file (str): Path to the CSV file with image names and labels.\n",
        "            transform (callable, optional): Optional transform to be applied on the image.\n",
        "        \"\"\"\n",
        "        self.img_folder = img_folder\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Extract image file names and labels from the CSV file\n",
        "        self.img_files = self.df['Image'].values\n",
        "        self.labels = self.df['any'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the length of the dataset (number of samples)\n",
        "        return len(self.img_files)\n",
        "    def __getitem__(self, index):\n",
        "    # Load the image file\n",
        "        img_filename = self.img_files[index]\n",
        "        img_path = os.path.join(self.img_folder, f\"{img_filename}.npy\")  # Construct the .npy file path\n",
        "\n",
        "    # Load the image as a NumPy array from the .npy file\n",
        "        image = np.load(img_path)\n",
        "        num_angles = image.shape[0]\n",
        "        num_channels = image.shape[2]\n",
        "        for angle_index in range(num_angles):\n",
        "                # Iterate over each channel\n",
        "            for channel_index in range(num_channels):\n",
        "                    # Apply Fourier transform to the current channel at the current angle\n",
        "                image[angle_index, :, channel_index] = abs(fft(image[angle_index, :, channel_index]))\n",
        "\n",
        "    # Convert the NumPy array to a PyTorch tensor\n",
        "\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image=image.permute(2,0,1)\n",
        "\n",
        "    # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "    # Get the label\n",
        "        label = self.labels[index]\n",
        "\n",
        "    # Convert the label to a PyTorch tensor (if necessary)\n",
        "        #label = torch.tensor(label, dtype=torch.float32)\n",
        "        label = torch.tensor([label], dtype=torch.float32)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fGeVVz__qzW"
      },
      "outputs": [],
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    # transforms.Resize((360, 362)), # Resize to match input size\n",
        "    transforms.ToTensor(), # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN_2OCgO_qzX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "\n",
        "train_img_folder ='/mnt/DATA/sinograms_3W_train'  # Replace with your image folder path\n",
        "train_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/train_x.csv'  # Replace with your CSV file path\n",
        "train_dataset = CustomDataset(train_img_folder, train_csv_file,transform=preprocess)\n",
        "\n",
        "test_img_folder ='/mnt/DATA/EE21B040/Downloads/sinograms_3W_test' # Replace with your image folder path\n",
        "test_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/test_x.csv' # Replace with your CSV file path\n",
        "test_dataset = CustomDataset(test_img_folder, test_csv_file,transform=preprocess)\n",
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=True,drop_last=True)\n",
        "\n",
        "# Set the random seed for reproducibility (optional)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Get the length of your train_dataset\n",
        "dataset_length = len(train_dataset)\n",
        "\n",
        "# Generate a list of indices from 0 to dataset_length\n",
        "indices = list(range(dataset_length))\n",
        "\n",
        "# Shuffle the indices\n",
        "torch.random.manual_seed(42)  # Set random seed for reproducibility\n",
        "# torch.random.shuffle(indices)\n",
        "indices = torch.randperm(dataset_length)\n",
        "indices = indices.tolist()\n",
        "# Select 20,000 random indices\n",
        "selected_indices = indices[:120000]\n",
        "\n",
        "# Create a SubsetRandomSampler using the selected indices\n",
        "subset_sampler = SubsetRandomSampler(selected_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, sampler=subset_sampler,drop_last=True)\n",
        "valid_img_folder ='/mnt/DATA/sinograms_3W_train'  # Replace with your image folder path\n",
        "valid_csv_file = '/mnt/DATA/ee21b040/Desktop/Chandra/DLH/valid_x.csv' # Replace with your CSV file path\n",
        "valid_dataset = CustomDataset(valid_img_folder, valid_csv_file,transform=preprocess)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=50, shuffle=True,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy9U7F4u_qzX",
        "outputId": "4c16ae14-7b2e-490c-b512-21d9667b3071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ],
      "source": [
        "# Define transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    # transforms.Resize((360, 362)), # Resize to match input size\n",
        "    transforms.ToTensor(), # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize\n",
        "])\n",
        "\n",
        "# Initialize the EfficientNet model\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=1) # 2 classes for binary classification\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iQD7Ijt_qzY",
        "outputId": "5117f96f-a0c9-44a1-e1e8-8ea8351932e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Instantiate the model and move it to the device\n",
        "model = model.to(device)\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViAjpIQ4_qzY"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(epoch):\n",
        "    torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkM2P9ti_qzZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lists to store training and validation accuracies and losses\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "# The rest of your code...\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Start the timer for the epoch\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    # Training loop\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move images and labels to the device (GPU or CPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Reshape labels to match model output shape\n",
        "        labels = labels.view(-1, 1)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        predictions = (outputs >= 0.5).float()  # Apply threshold to outputs\n",
        "        train_correct += (predictions == labels.float()).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy and loss\n",
        "    train_accuracy = train_correct / train_total\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            # Move images and labels to the device (GPU or CPU)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            labels = labels.view(-1, 1)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate the number of correct predictions\n",
        "            predictions = (outputs >= 0.5).float()  # Apply threshold to outputs\n",
        "            val_correct += (predictions == labels.float()).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    # Calculate validation accuracy and loss\n",
        "    val_accuracy = val_correct / val_total\n",
        "    val_losses.append(val_loss / len(valid_loader))\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    # Print progress\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
        "          f'Train Loss: {train_losses[-1]:.4f}, '\n",
        "          f'Train Accuracy: {train_accuracies[-1]:.4f}, '\n",
        "          f'Validation Loss: {val_losses[-1]:.4f}, '\n",
        "          f'Validation Accuracy: {val_accuracies[-1]:.4f}')\n",
        "\n",
        "    # Calculate and print the time taken for the epoch\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f'Epoch {epoch + 1} completed in {epoch_time:.2f} seconds')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training and validation losses\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracies\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Training Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'final_model.pth')\n",
        "print(\"Final model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kocICo9__qzZ"
      },
      "outputs": [],
      "source": [
        "# Evaluation on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dlh_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}